version: '3'
services:
  # zookeeper:
  #   image: confluentinc/cp-zookeeper:latest
  #   environment:
  #     ZOOKEEPER_CLIENT_PORT: 2181
  #     ZOOKEEPER_TICK_TIME: 2000
  #   volumes:
  #     - zookeeper-data:/var/lib/zookeeper/data
  #     - zookeeper-log:/var/lib/zookeeper/log

  kafka1:
    image: confluentinc/cp-kafka:7.3.3
    # depends_on:
    ports:
      - 9092:9092
      - 29092:29092 # for contro
    #   - zookeeperller
    environment:
      # KAFKA_BROKER_ID: 1
      KAFKA_KRAFT_MODE: true
      KAFKA_NODE_ID: 1
      # KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_LISTENERS: PLAINTEXT://kafka1:29092,PLAINTEXT_HOST://0.0.0.0:9092
      # KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka1:29092,PLAINTEXT_HOST://localhost:9092

      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1 # new config for kraft
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1 # new config for kraft
      KAFKA_PROCESS_ROLES: broker,controller
      KAFKA_CONTROLLER_QUORUM_VOTERS: 1@kafka1:29093
      KAFKA_LOG_DIRS: /tmp/kraft-combined-logs
      CLUSTER_ID: MkU3OEVBNTcwNTJENDM2Qk
      KAFKA_OPTS: "-Dkafka.kraft.cluster.id=MkU3OEVBNTcwNTJENDM2Qk"
    # command:
    #   - sh
    #   - -c 
    #   - usr/bin/kafka-storage format -t KAFKA_CLUSTER_ID -c config/kraft/server.properties
    healthcheck:
      test: ["CMD", "kafka-topics", "--bootstrap-server", "localhost:9092", "--list"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
    volumes:
      - kafka-data:/var/lib/kafka/data 

  postgres:
    image: postgres:latest
    ports:
      - 5432:5432
    environment:
      POSTGRES_DB: logs_db
      POSTGRES_USER: user
      POSTGRES_PASSWORD: password
    volumes:
      - postgres-data:/var/lib/postgresql/data

  schema-registry:
    image: confluentinc/cp-schema-registry:latest
    hostname: schema-registry
    depends_on:
      kafka1:
        condition: service_healthy
    ports:
      - "8081:8081"
    environment:
      SCHEMA_REGISTRY_HOST_NAME: schema-registry
      # SCHEMA_REGISTRY_KAFKASTORE_CONNECTION_URL: 'zookeeper:2181'
      SCHEMA_REGISTRY_LISTENERS: http://0.0.0.0:8081
      SCHEMA_REGISTRY_KAFKASTORE_BOOTSTRAP_SERVERS: kafka:29092
      SCHEMA_REGISTRY_DEBUG: 'true'
    healthcheck:
      test: curl --output /dev/null --silent --head --fail http://schema-registry:8081/subjects
      interval: 30s
      timeout: 10s
      retries: 3

  kafka-connect:
    image: confluentinc/cp-kafka-connect:latest
    depends_on:
      kafka1:
        condition: service_healthy
      schema-registry:
        condition: service_healthy
      postgres:
        condition: service_started
    ports:
      - 8083:8083
    environment:
      CONNECT_BOOTSTRAP_SERVERS: kafka1:29092
      CONNECT_REST_PORT: 8083
      CONNECT_GROUP_ID: kafka-connect
      CONNECT_CONFIG_STORAGE_TOPIC: _connect-configs
      CONNECT_OFFSET_STORAGE_TOPIC: _connect-offsets
      CONNECT_STATUS_STORAGE_TOPIC: _connect-status
      CONNECT_REST_ADVERTISED_HOST_NAME: kafka-connect
      CONNECT_LOG4J_ROOT_LOGLEVEL: INFO
      CONNECT_LOG4J_LOGGERS: org.apache.kafka.connect.runtime.rest=WARN,org.reflections=ERROR
      CONNECT_PLUGIN_PATH: /usr/share/java,/usr/share/confluent-hub-components,/connectors
      CONNECT_CONFIG_STORAGE_REPLICATION_FACTOR: 1
      CONNECT_OFFSET_STORAGE_REPLICATION_FACTOR: 1
      CONNECT_STATUS_STORAGE_REPLICATION_FACTOR: 1
      # config 
      CONNECT_KEY_CONVERTER: org.apache.kafka.connect.storage.StringConverter
      CONNECT_VALUE_CONVERTER: io.confluent.connect.avro.AvroConverter
      CONNECT_VALUE_CONVERTER_SCHEMA_REGISTRY_URL: http://schema-registry:8081
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8083/connectors"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
    volumes:
      - ./connectors:/connectors
    command:
      - bash
      - -c
      - |
        # add require dependencies
        echo "Installing required dependencies"
        apk update && apk add curl jq python3 py3-pip
        #
        echo "Installing connector plugins"
        confluent-hub install --no-prompt confluentinc/kafka-connect-jdbc:latest
        #
        echo "Launching Kafka Connect worker"
        /etc/confluent/docker/run &
        #
        echo "Waiting for Kafka Connect to start listening on localhost"
        while : ; do
          curl_status=$$(curl -s -o /dev/null -w %{http_code} http://localhost:8083/connectors)
          echo -e $$(date) " Kafka Connect listener HTTP state: " $$curl_status " (waiting for 200)"
          if [ $$curl_status -eq 200 ] ; then
            break
          fi
          sleep 5
        done
        #
        echo "Creating PostgreSQL sink connector"
        if [ $(curl -X GET http://localhost:8083/connectors/postgres-sink/status | jq .error_code) == '404' ]; then
          # no postgresql sink connector found
          # configure from scratch
          echo "initialising the sink..."
          curl -X POST http://localhost:8083/connectors -H "Content-Type: application/json" -d @/connectors/postgres-sink-config.json
        else
          # sink connector already exists
          # update the configuration
          echo "reconfiguring the sink..."
          d=$(jq -r .config connectors/postgres-sink-config.json)
          curl -X PUT http://localhost:8083/connectors/postgres-sink/config -H "Content-Type: application/json" -d "${d}"

          echo "restarting the sink..."
          curl -X POST http://localhost:8083/connectors/postgres-sink/restart
          
          echo "checking the sink status..."
          curl -X GET http://localhost:8083/connectors/postgres-sink/status
        fi
        #
        sleep infinity

  stream-connector:
    build:
      context: ./stream-connector
      dockerfile: Dockerfile
    ports:
      - "3000:3000"
    depends_on:
      kafka1:
        condition: service_healthy
      kafka-connect:
        condition: service_healthy
    environment:
      FASTIFY_PORT: $APP_PORT
      FASIFTY_ADDRESS: $APP_HOST
      KAFKA_BROKER: kafka1:29092
      SCHEMA_REGISTRY: http://schema-registry:8081
      RPC_MAINNET_WS: $RPC_MAINNET_WS
      RPC_MAINNET_HTTP: $RPC_MAINNET_HTTP
    volumes:
      - ./stream-connector:/app

  schema-registry-ui:
    image: landoop/schema-registry-ui
    container_name: schema-registry-ui
    depends_on:
      schema-registry:
        condition: service_healthy
    ports:
      - "8000:8000"
    environment:
      - SCHEMAREGISTRY_URL=http://schema-registry:8081
      - PROXY=true

networks:
  default:
    name: kafka-network

volumes:
  postgres-data:
  kafka-data:
  # zookeeper-data:
  # zookeeper-log:
